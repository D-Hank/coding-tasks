import math

from tqdm import tqdm

from concurrent.futures import ThreadPoolExecutor, as_completed
from human_eval.data import read_problems, stream_jsonl, write_jsonl

from execute import run_code

import_lib = ""

# Compute pass@k score of a certain problem
def compute_score(n: int, c: int, k: int) -> float:
    # Simple cases
    if k > n or c == 0:
        return 0.0
    
    if n - c < k:
        return 1.0

    return 1 - math.comb(n - c, k) / math.comb(n, k)

def evaluate(k = 1, num_workers = 8) -> float:
    # Read dataset input
    problems = read_problems("../../datasets/humaneval/HumanEval.jsonl")
    # Read samples generated by LLM
    samples = stream_jsonl("samples.jsonl")
    task_ids = problems.keys()
    # n and c of each task
    task_n_c = {task_id : {"n" : 0, "c" : 0} for task_id in task_ids}

    # Unique ID in queue
    order = 0
    # Output to file
    output = []
    # Put all tasks in queue, assign our worker processes to them
    with ThreadPoolExecutor(num_workers) as pool:
        procs = []
        for sample in tqdm(samples):
            task_id = sample["task_id"]
            completion = sample["completion"]

            # Fetch input
            problem = problems[task_id]
            prompt = problem["prompt"]
            test = problem["test"]
            candidate = problem["entry_point"]
            code = import_lib + "\n" + prompt + "\n" + completion + "\n" + test + "\ncheck(" + candidate + ")\n"

            # Submit to process
            proc = pool.submit(run_code, order, code)
            procs.append(proc)

            #if order == 55:
            #    print(code)

            line = sample.copy()
            output.append(line)

            order += 1

        # Check each process's status
        for stat in tqdm(as_completed(procs), total=order):
            # No need to save info to compute score
            order, ret = stat.result()
            task_id = output[order]["task_id"]
            task_n_c[task_id]["n"] += 1
            task_n_c[task_id]["c"] += int(ret[0])

            line = output[order]
            line["result"] = ret[1]
            line["passed"] = ret[0]

            #if order == 55:
            #    print(ret)

    # Compute pass@k of each problem
    scores = []
    for nc in task_n_c.values():
        n, c = nc["n"], nc["c"]
        score = compute_score(n, c, k)
        scores.append(score)

    write_jsonl("result.jsonl", output)

    return sum(scores) / len(scores)

if __name__ == "__main__":
    pass_k = evaluate()
    print("pass@1:", pass_k)
